<!DOCTYPE html>
<html>
<head>
	<title>Publications | Matteo Dunnhofer</title>

	<!-- heading -->
	<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=yes">
<link href="https://matteo-dunnhofer.github.io/assets/css/main.css" rel="stylesheet" type="text/css">
<link href="https://matteo-dunnhofer.github.io/assets/css/main-phone.css" rel="stylesheet" type="text/css">
<link href="https://matteo-dunnhofer.github.io/assets/css/main-tablet.css" rel="stylesheet" type="text/css">
<link href="https://matteo-dunnhofer.github.io/assets/css/main-desktop.css" rel="stylesheet" type="text/css">

<meta name="author" content="Matteo Dunnhofer" >
<meta name="keywords" content="computer science, artificial intelligence, machine learning, deep learning, reinforcement learning, computer vision, visual object tracking, medical image analysis, skateboarding, tarvisio, udine, uniud">
<link rel="shortcut icon" href="https://matteo-dunnhofer.github.io/assets/images/logos/brackets_logo.jpg" />

<!-- google analytics -->
<?php include_once("analyticstracking.php") ?>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>

<!-- Computer Modern Serif-->
<!-- <link rel="stylesheet" href="assets/fonts/Serif/cmun-serif.css"></link> -->

<!-- Ubuntu Mono font -->
<link href='https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700' rel='stylesheet' type='text/css'>

<!-- <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@700&display=swap" rel="stylesheet"> -->

<link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">


<!-- MathJax -->
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!-- cookie consent bar -->
<!--
<link href="css/cookie-consent.css" rel="stylesheet" type="text/css">
<?php require_once("cookie-consent.php") ?> -->

	<meta name="description" content="Matteo Dunnhofer's selected publications.">

	<link href="https://matteo-dunnhofer.github.io/assets/css/publications.css" rel="stylesheet" type="text/css">
</head>
<body>
	<!-- header bar -->
	<!-- header block -->
<div class="header">
	<div class="title">
		<a href="https://matteo-dunnhofer.github.io/index.html"><h3 class="content-title-main" id="left-bracket">{</h3>
                        <h3 class="content-title-main" id="bracket-content">matteo-dunnhofer</h3>
                        <h3 class="content-title-main" id="right-bracket">}</h3></a>
	</div>
	
	<div class="dropdown">
		<div class="content-block">
			<img src="https://matteo-dunnhofer.github.io/assets/images/logos/hamburger.png" class="logo-hamburger">
  			<!-- <h3 class="content-title">Contents</h3> -->
  		</div>
	</div>

  <div class="dropdown-content">
    <!-- <a class="menu-item" href="about.html"><pre><h4>1  About</h4></pre></a> -->
    <!-- <a class="menu-item" href="software.php"><pre><h4><b>2  Software</b></h4></pre></a> -->
    <a class="menu-item" href="https://matteo-dunnhofer.github.io/publications.html"><p class="menu-item-p" ><b>Publications</b></p></a>
    <a class="menu-item" href="https://matteo-dunnhofer.github.io/blog"><p class="menu-item-p" ><b>Blog</b></p></a>
    <a class="menu-item" href="https://matteo-dunnhofer.github.io/contact.html"><p class="menu-item-p" ><b>Contact</b></p></a>
  </div>

  <hr style="height : 1px ; color : black ; background-color : black" >
</div>

<!-- menu click handler -->
<script> 
  $( document ).ready(function() {
    $('.content-block').click(function() {
      $('.dropdown-content').toggleClass('click');
    });
  });
  $( document ).ready(function() {
    $('.content-block').hover(function() {
      $('.dropdown-content').toggleClass('hover');
    });
  });
  $( document ).ready(function() {
    $('.dropdown-content').hover(function() {
      $('.dropdown-content').toggleClass('hover');
    });
  });
</script>

	<div class="container-pubs" id="pubs-container-title-div">
    <div class="pubs-div" id="pubs-title-div" style="height: 20px; padding-bottom: 20px">
        <p id="page-title">On this page you can find some selected publications. For a complete list, you can check <a class="normal-link" href='publications-all.html'>this link</a> or <a class="normal-link" href='https://scholar.google.com/citations?user=GIhkF8UAAAAJ'>my Google Scholar profile</a>.</p>
    </div>
</div>

<div class="container-pubs">

    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/midl2021.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">Improving MRI-based Knee Disorder Diagnosis with Pyramidal Feature Details</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, and Christian Micheloni</h4>
                        <h4 class="pubs-where" id="text-where">International Conference on Medical Imaging with Deep Learning (MIDL) 2021</h4>
                        
                             <h4 class="pubs-desc" id="text-desc">We present a plug-and-play CNN architecture to better extract features related to knee anomalies when imaged with MRI. Our strategy allows to improve the diagnostic performance of baseline CNNs.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://openreview.net/forum?id=7psPmlNffvg">[link]</a></h4>
                            

                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://drive.google.com/file/d/1dd3WkrKA3DbC_PQuiAQ8vTe4j2MxBhLM/view?usp=sharing">[poster]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/dontfollowmeimcrazy/MRPyrNet">[code]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://2021.midl.io/papers/j6">[project page]</a></h4>
                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/ral2021.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Journal paper</h5>
                        <h4 class="pubs-title" id="text-title">Weakly-Supervised Domain Adaptation of Deep Regression Trackers via Reinforced Knowledge Distillation</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, and Christian Micheloni</h4>
                        <h4 class="pubs-where" id="text-where">IEEE Robotics and Automation Letters</h4>
                        
                             <h4 class="pubs-desc" id="text-desc">We propose the first solution to adapt the generic knowledge of deep regression trackers to particular and small data vision domains.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://ieeexplore.ieee.org/document/9394708">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="http://arxiv.org/abs/2103.14496">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/3T3BJudDSwQ">[video]</a></h4>
                            

                            

                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/trek100.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Preprint paper</h5>
                        <h4 class="pubs-title" id="text-title">Is First Person Vision Challenging for Object Tracking? The TREK-100 Benchmark Dataset</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Antonino Furnari, Giovanni Maria Farinella, and Christian Micheloni</h4>
                        <h4 class="pubs-where" id="text-where">arXiv</h4>
                        
                             <h4 class="pubs-desc" id="text-desc">We present a systematic and extended study on the impact of the first person viewpoint and context on state-of-the-art visual tracking algorithms.</h4>
                        

                        <div class="pubs-links">
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://arxiv.org/abs/2011.12263">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/SW5jLh6-bkg">[video]</a></h4>
                            

                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://machinelearning.uniud.it/datasets/trek100/">[project page]</a></h4>
                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/vot-kd-rl.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">Tracking-by-Trackers with a Distilled and Reinforced Model</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, and Christian Micheloni</h4>
                        <h4 class="pubs-where" id="text-where">Asian Conference on Computer Vision (ACCV) 2020</h4>
                        
                             <h4 class="pubs-desc" id="text-desc">A new visual tracking methodology in which off-the-shelf trackers are considered as building blocks and as source of information is proposed in this paper.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://openaccess.thecvf.com/content/ACCV2020/html/Dunnhofer_Tracking-by-Trackers_with_a_Distilled_and_Reinforced_Model_ACCV_2020_paper.html">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://arxiv.org/abs/2007.04108">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/VzeoHQQl-rA">[video]</a></h4>
                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/dontfollowmeimcrazy/vot-kd-rl">[code]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://accv2020.github.io/miniconf/poster_141.html">[project page]</a></h4>
                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/VOT2020.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">An Exploration of Target-Conditioned Segmentation Methods for Visual Object Trackers</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, and Christian Micheloni</h4>
                        <h4 class="pubs-where" id="text-where">European Conference on Computer Vision (ECCV) 2020, Visual Object Tracking Challenge VOT2020 workshop</h4>
                        
                             <h4 class="pubs-desc" id="text-desc">We present an extensive study on how to transform bounding-box visual trackers into trackers able to output segmentations.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://link.springer.com/chapter/10.1007%2F978-3-030-68238-5_41">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="http://arxiv.org/abs/2008.00992">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/9af8zsoXeE8">[video]</a></h4>
                            

                            

                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/siamunet.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Journal paper</h5>
                        <h4 class="pubs-title" id="text-title">Siam-U-Net: encoder-decoder siamese network for knee cartilage tracking in ultrasound images</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Maria Antico, Fumio Sasazawa, Yu Takeda, Saskia Camps, Niki Martinel, Christian Micheloni, Gustavo Carneiro, and Davide Fontanarosa</h4>
                        <h4 class="pubs-where" id="text-where">Medical Image Analysis</h4>
                        
                             <h4 class="pubs-desc" id="text-desc">We combine the U-Net architecture and the siamese visual tracking framework to develop the first algorithm able to track the knee cartilage in ultrasound videos.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://www.sciencedirect.com/science/article/abs/pii/S1361841519301677">[link]</a></h4>
                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/nYTlEyMoj0s">[video]</a></h4>
                            

                            

                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/iccv-w-2019.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">Visual Tracking by means of Deep Reinforcement Learning and an Expert Demonstrator</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, Gian Luca Foresti, and Christian Micheloni</h4>
                        <h4 class="pubs-where" id="text-where">IEEE/CVF International Conference on Computer Vision (ICCV) 2019, Visual Object Tracking Challenge VOT2019 workshop</h4>
                        
                             <h4 class="pubs-desc" id="text-desc">A new learning end-to-end strategy is presented here to develop reinforcement learning based visual trackers.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="http://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Dunnhofer_Visual_Tracking_by_Means_of_Deep_Reinforcement_Learning_and_an_ICCVW_2019_paper.html">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://arxiv.org/abs/1909.08487">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/jSGLafk4-G4">[video]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://drive.google.com/file/d/1TLq1UtptYcSr2wMEnRfIatCZJpwV7Z88/view?usp=sharing">[poster]</a></h4>
                            

                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
    
</div>

	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-82663987-1', 'auto');
  ga('set', 'anonymizeIp', true);
  ga('send', 'pageview');

</script>

</body>
</html>