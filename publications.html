<!DOCTYPE html>
<html>
<head>
	<title>Publications | Matteo Dunnhofer</title>

	<!-- heading -->
	<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=yes">
<link href="https://matteo-dunnhofer.github.io/assets/css/main.css" rel="stylesheet" type="text/css">
<link href="https://matteo-dunnhofer.github.io/assets/css/main-phone.css" rel="stylesheet" type="text/css">
<link href="https://matteo-dunnhofer.github.io/assets/css/main-tablet.css" rel="stylesheet" type="text/css">
<link href="https://matteo-dunnhofer.github.io/assets/css/main-desktop.css" rel="stylesheet" type="text/css">

<meta name="author" content="Matteo Dunnhofer" >
<meta name="keywords" content="computer science, artificial intelligence, machine learning, deep learning, reinforcement learning, computer vision, visual object tracking, medical image analysis, skateboarding, tarvisio, udine, uniud">
<link rel="shortcut icon" href="https://matteo-dunnhofer.github.io/assets/images/logos/brackets_logo.jpg" />

<!-- google analytics -->
<?php include_once("analyticstracking.php") ?>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>

<!-- Computer Modern Serif-->
<!-- <link rel="stylesheet" href="assets/fonts/Serif/cmun-serif.css"></link> -->

<!-- Ubuntu Mono font -->
<link href='https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700' rel='stylesheet' type='text/css'>

<!-- <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@700&display=swap" rel="stylesheet"> -->

<link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">


<!-- MathJax -->
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!-- cookie consent bar -->
<!--
<link href="css/cookie-consent.css" rel="stylesheet" type="text/css">
<?php require_once("cookie-consent.php") ?> -->

	<meta name="description" content="Matteo Dunnhofer's selected publications.">

	<link href="https://matteo-dunnhofer.github.io/assets/css/publications.css" rel="stylesheet" type="text/css">
</head>
<body>
	<!-- header bar -->
	<!-- header block -->
<div class="header">
	<div class="title">
		<a href="https://matteo-dunnhofer.github.io/index.html"><h3 class="content-title-main" id="left-bracket">{</h3>
                        <h3 class="content-title-main" id="bracket-content">matteo-dunnhofer</h3>
                        <h3 class="content-title-main" id="right-bracket">}</h3></a>
	</div>
	
	<div class="dropdown">
		<div class="content-block">
			<img src="https://matteo-dunnhofer.github.io/assets/images/logos/hamburger.png" class="logo-hamburger">
  			<!-- <h3 class="content-title">Contents</h3> -->
  		</div>
	</div>

  <div class="dropdown-content">
    <!-- <a class="menu-item" href="about.html"><pre><h4>1  About</h4></pre></a> -->
    <!-- <a class="menu-item" href="software.php"><pre><h4><b>2  Software</b></h4></pre></a> -->
    <a class="menu-item" href="https://matteo-dunnhofer.github.io/publications.html"><p class="menu-item-p" ><b>Publications</b></p></a>
    <a class="menu-item" href="https://matteo-dunnhofer.github.io/initiatives.html"><p class="menu-item-p" ><b>Initiatives</b></p></a>
    <a class="menu-item" href="https://matteo-dunnhofer.github.io/blog"><p class="menu-item-p" ><b>Blog</b></p></a>
    <a class="menu-item" href="https://matteo-dunnhofer.github.io/contact.html"><p class="menu-item-p" ><b>Contacts</b></p></a>
  </div>

  <hr style="height : 1px ; color : black ; background-color : black" >
</div>

<!-- menu click handler -->
<script> 
  $( document ).ready(function() {
    $('.content-block').click(function() {
      $('.dropdown-content').toggleClass('click');
    });
  });
  $( document ).ready(function() {
    $('.content-block').hover(function() {
      $('.dropdown-content').toggleClass('hover');
    });
  });
  $( document ).ready(function() {
    $('.dropdown-content').hover(function() {
      $('.dropdown-content').toggleClass('hover');
    });
  });
</script>

	<div class="container-pubs" id="pubs-container-title-div">
    <div class="pubs-div" id="pubs-title-page-div">
        <h1 class="pubs-page-title-h">Publications</h1>
    </div>
    <div class="pubs-div" id="pubs-title-div" style="height: 20px;">
        <p id="page-title">On this page you can find some selected publications with relative resources. For a complete list of papers, you can check <a class="normal-link" href='publications-all.html'>this link</a> or <a class="normal-link" href='https://scholar.google.com/citations?user=GIhkF8UAAAAJ'>my Google Scholar profile</a>.</p>
    </div>
</div>

<div class="container-pubs">

    <div class="pubs-div" id="pubs-title-div" style="height: 20px; padding-bottom: 30px">
        <h2 class="init-page-title-h">Journal papers</h2>
    </div>

    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/ijcv2022.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Journal paper</h5>
                        <h4 class="pubs-title" id="text-title">Visual Object Tracking in First Person Vision</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Antonino Furnari, Giovanni Maria Farinella, and Christian Micheloni</h4>
                        
                        
                             <h4 class="pubs-where" id="text-where">International Journal of Computer Vision (2023)</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">Extended version of our ICCVW 2021 paper about the impact of the first-person viewpoint on object tracking algorithms.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://link.springer.com/article/10.1007/s11263-022-01694-6">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://arxiv.org/abs/2209.13502">[arXiv preprint]</a></h4>
                            

                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/matteo-dunnhofer/TREK-150-toolkit">[code]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://machinelearning.uniud.it/datasets/trek150/">[project page]</a></h4>
                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/cmig2022.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Journal paper</h5>
                        <h4 class="pubs-title" id="text-title">Deep convolutional feature details for better knee disorder diagnoses in magnetic resonance images</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, and Christian Micheloni</h4>
                        
                        
                             <h4 class="pubs-where" id="text-where">Computerized Medical Imaging and Graphics (2022)</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">This paper extends our MIDL 2021 work about employing knee-specific CNN architectures for a better extraction of features related to knee anomalies. Here we present also a model interpretation strategy.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://www.sciencedirect.com/science/article/abs/pii/S0895611122001124">[link]</a></h4>
                            

                            

                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/matteo-dunnhofer/MRPyrNet">[code]</a></h4>
                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/imavis.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Journal paper</h5>
                        <h4 class="pubs-title" id="text-title">Combining Complementary Trackers for Enhanced Long-Term Visual Object Tracking</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Kristian Simonato, and Christian Micheloni</h4>
                        
                        
                             <h4 class="pubs-where" id="text-where">Image and Vision Computing (2022)</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">Extended version of our ICPR 2022 paper about combining complementary trackers for enhanced long-term visual tracking.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://www.sciencedirect.com/science/article/pii/S0262885622000774">[link]</a></h4>
                            

                            

                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/matteo-dunnhofer/CoCoLoT">[code]</a></h4>
                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/ral2021.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Journal paper</h5>
                        <h4 class="pubs-title" id="text-title">Weakly-Supervised Domain Adaptation of Deep Regression Trackers via Reinforced Knowledge Distillation</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, and Christian Micheloni</h4>
                        
                        
                             <h4 class="pubs-where" id="text-where">IEEE Robotics and Automation Letters (2021)</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">We propose the first solution to adapt the generic knowledge of deep regression trackers to particular and small data vision domains. Reinforcement learning is used to express weak supervision and knowledge distillation to maintain learning stability.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://ieeexplore.ieee.org/document/9394708">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="http://arxiv.org/abs/2103.14496">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/3T3BJudDSwQ">[video]</a></h4>
                            

                            

                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/siamunet.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Journal paper</h5>
                        <h4 class="pubs-title" id="text-title">Siam-U-Net: encoder-decoder siamese network for knee cartilage tracking in ultrasound images</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Maria Antico, Fumio Sasazawa, Yu Takeda, Saskia Camps, Niki Martinel, Christian Micheloni, Gustavo Carneiro, and Davide Fontanarosa</h4>
                        
                        
                             <h4 class="pubs-where" id="text-where">Medical Image Analysis (2020)</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">This study proposes a new deep learning method to track, accurately and efficiently, the femoral condyle cartilage in ultrasound sequences, which were acquired under several clinical conditions, mimicking realistic surgical setups.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://www.sciencedirect.com/science/article/abs/pii/S1361841519301677">[link]</a></h4>
                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/nYTlEyMoj0s">[video]</a></h4>
                            

                            

                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
    


    <div class="pubs-div" id="pubs-title-div" style="height: 20px; padding-bottom: 30px">
        <h2 class="init-page-title-h">Conference papers</h2>
    </div>

    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/wacv2024.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">Tracking Skiers from the Top to the Bottom</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Luca Sordi, Niki Martinel, and Christian Micheloni</h4>
                        
                        
                            <h4 class="pubs-where" id="text-where">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2024</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">In this paper, we perform a study over visual object tracking algorithms to localize skiers in multi-camera videos capturing their complete performance, from the top to the bottom of the course.</h4>
                        

                        <div class="pubs-links">
                            

                            

                            

                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://machinelearning.uniud.it/datasets/skitb/">[project page]</a></h4>
                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/cvpr2023.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">Visualizing Skiers' Trajectories in Monocular Videos</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Luca Sordi, and Christian Micheloni</h4>
                        
                        
                            <h4 class="pubs-where" id="text-where">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2023, CVsports workshop</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">In this paper, we describe an algorithm capable of showing the trajectory performed by an alpine skier in a video capturing its performance.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://openaccess.thecvf.com/content/CVPR2023W/CVSports/html/Dunnhofer_Visualizing_Skiers_Trajectories_in_Monocular_Videos_CVPRW_2023_paper.html">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://arxiv.org/abs/2304.02994">[arXiv preprint]</a></h4>
                            

                            

                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://machinelearning.uniud.it/projects/eyof2023/">[project page]</a></h4>
                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/icpr2022.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">CoCoLoT: Combining Complementary Trackers in Long-Term Visual Tracking</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer and Christian Micheloni</h4>
                        
                        
                            <h4 class="pubs-where" id="text-where">International Conference on Pattern Recognition (ICPR) 2022</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">In this paper, we present a long-term tracking methodology that combines the complementary capabilities of different trackers to achieve more robust tracking performance. We used this solution for winning the VOT2021 long-term challenge.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://ieeexplore.ieee.org/document/9956082">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://arxiv.org/abs/2205.04261">[arXiv preprint]</a></h4>
                            

                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/matteo-dunnhofer/CoCoLoT">[code]</a></h4>
                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/trek100.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">Is First Person Vision Challenging for Object Tracking?</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Antonino Furnari, Giovanni Maria Farinella, and Christian Micheloni</h4>
                        
                        
                            <h4 class="pubs-where" id="text-where">IEEE/CVF International Conference on Computer Vision (ICCV) 2021, Visual Object Tracking Challenge VOT2021 workshop</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">We present the first systematic study about the impact of the first person viewpoint on state-of-the-art visual tracking algorithms.</h4>
                        

                        <div class="pubs-links">
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://arxiv.org/abs/2108.13665">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://www.youtube.com/watch?v=oX1nICHgEJM">[video]</a></h4>
                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/matteo-dunnhofer/TREK-150-toolkit">[code]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://machinelearning.uniud.it/datasets/trek150/">[project page]</a></h4>
                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/vot2021.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">The Ninth Visual Object Tracking VOT2021 Challenge Results</h4>
                        <h4 class="pubs-author" id="text-author">Matej Kristan, Jiří Matas, Aleš Leonardis, Michael Felsberg, Roman Pflugfelder, Joni-Kristian Kämäräinen, Hyung Jin Chang, Martin Danelljan, ..., Matteo Dunnhofer, ...</h4>
                        
                        
                            <h4 class="pubs-where" id="text-where">IEEE/CVF International Conference on Computer Vision (ICCV) 2021, Visual Object Tracking Challenge VOT2021 workshop</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">This paper surveys the state-of-the-art in visual object tracking for year 2021. It includes the description of our winning solution to the long-term challenge mlpLT.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://openaccess.thecvf.com/content/ICCV2021W/VOT/html/Kristan_The_Ninth_Visual_Object_Tracking_VOT2021_Challenge_Results_ICCVW_2021_paper.html">[link]</a></h4>
                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/OvgKHj7lH9c">[video]</a></h4>
                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="http://data.votchallenge.net/vot2021/trackers/mlpLT-code-2021-05-28T15_09_23.381777.zip">[code]</a></h4>
                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/midl2021.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">Improving MRI-based Knee Disorder Diagnosis with Pyramidal Feature Details</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, and Christian Micheloni</h4>
                        
                        
                            <h4 class="pubs-where" id="text-where">International Conference on Medical Imaging with Deep Learning (MIDL) 2021</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">We present a plug-and-play CNN architecture to better extract features related to knee anomalies when imaged with MRI. Our strategy allows to improve the diagnostic performance of baseline CNNs.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://openreview.net/forum?id=7psPmlNffvg">[link]</a></h4>
                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://www.youtube.com/watch?v=XkHiyNDK2Xk">[video]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://drive.google.com/file/d/1dd3WkrKA3DbC_PQuiAQ8vTe4j2MxBhLM/view?usp=sharing">[poster]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/matteo-dunnhofer/MRPyrNet">[code]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://2021.midl.io/papers/j6">[project page]</a></h4>
                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/vot-kd-rl.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">Tracking-by-Trackers with a Distilled and Reinforced Model</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, and Christian Micheloni</h4>
                        
                        
                            <h4 class="pubs-where" id="text-where">Asian Conference on Computer Vision (ACCV) 2020</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">This paper proposes a novel tracking methodology that takes advantage of other visual trackers, offline and online, and extensive validation shows that the proposed algorithms compete with real-time state-of-the-art trackers.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://openaccess.thecvf.com/content/ACCV2020/html/Dunnhofer_Tracking-by-Trackers_with_a_Distilled_and_Reinforced_Model_ACCV_2020_paper.html">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://arxiv.org/abs/2007.04108">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/VzeoHQQl-rA">[video]</a></h4>
                            

                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/matteo-dunnhofer/vot-kd-rl">[code]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://accv2020.github.io/miniconf/poster_141.html">[project page]</a></h4>
                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/VOT2020.jpg" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">An Exploration of Target-Conditioned Segmentation Methods for Visual Object Trackers</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, and Christian Micheloni</h4>
                        
                        
                            <h4 class="pubs-where" id="text-where">European Conference on Computer Vision (ECCV) 2020, Visual Object Tracking Challenge VOT2020 workshop</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">We present an extensive study on how to transform bounding-box visual trackers into trackers able to output segmentations.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://link.springer.com/chapter/10.1007%2F978-3-030-68238-5_41">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="http://arxiv.org/abs/2008.00992">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/9af8zsoXeE8">[video]</a></h4>
                            

                            

                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
            <div class="container-2-pubs">
                <div class="pubs-div">
                    <img src="assets/images/pubs/iccv-w-2019.png" class="pubs-image">
                    
                    <div class="pubs-info-div">
                        <h5 class="pubs-type" id="text-type">Conference paper</h5>
                        <h4 class="pubs-title" id="text-title">Visual Tracking by means of Deep Reinforcement Learning and an Expert Demonstrator</h4>
                        <h4 class="pubs-author" id="text-author">Matteo Dunnhofer, Niki Martinel, Gian Luca Foresti, and Christian Micheloni</h4>
                        
                        
                            <h4 class="pubs-where" id="text-where">IEEE/CVF International Conference on Computer Vision (ICCV) 2019, Visual Object Tracking Challenge VOT2019 workshop</h4>
                        

                        
                             <h4 class="pubs-desc" id="text-desc">A new learning end-to-end strategy is presented here to develop reinforcement learning based visual trackers.</h4>
                        

                        <div class="pubs-links">
                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="http://openaccess.thecvf.com/content_ICCVW_2019/html/VOT/Dunnhofer_Visual_Tracking_by_Means_of_Deep_Reinforcement_Learning_and_an_ICCVW_2019_paper.html">[link]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://arxiv.org/abs/1909.08487">[arXiv preprint]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://youtu.be/jSGLafk4-G4">[video]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://drive.google.com/file/d/1TLq1UtptYcSr2wMEnRfIatCZJpwV7Z88/view?usp=sharing">[poster]</a></h4>
                            

                            
                                <h4 class="pubs-link" id="text-link"><a class="normal-link" href="https://github.com/matteo-dunnhofer/vot-kd-rl">[code]</a></h4>
                            

                            
                        </div>
                    </div>
                 </div>
            </div>
         
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
        
    </div>
    
</div>

	<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-82663987-1', 'auto');
  ga('set', 'anonymizeIp', true);
  ga('send', 'pageview');

</script>

</body>
</html>